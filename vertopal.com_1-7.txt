

    #Activation
    import numpy as np
    import matplotlib.pyplot as plt

    x= np.linspace(-6,6,2000)
    activations = {
        "sigmoid":(lambda x:(s:=1/(1+np.exp(-x)),s*(1-s))),
        "tanh":(lambda x:(t:=np.tanh(x),1-t**2)),
        "relu":(lambda x:(r:=np.maximum(0,x),(x>0).astype(float))),
        "leaky":(lambda x,a=0.025:(np.where(x>0,x,a*x),np.where(x>0,1,a*x))),
        "prelu":(lambda x,a=0.25:(np.where(x>0,x,a*x),np.where(x>0,1,a*x))),
        "elu":(lambda x,a=1.0:(np.where(x>0,x,a*(np.exp(x)-1)),np.where(x>0,1,a*np.exp(x)))),
        "softplus":(lambda x:(np.log1p(np.exp(x)),1/(1+np.exp(-x))))
    }
    for name,f in activations.items():
        y,dy = f(x)
        plt.plot(x,y,label=name)
        plt.plot(x,dy,label=f"derivate")
        plt.axhline(0,color='black')
        plt.axvline(0,color='black')
        plt.legend()
        plt.title(name)
        plt.show()

    #MLP
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense,Flatten
    from tensorflow.keras.datasets import mnist
    from tensorflow.keras.utils import to_categorical
    from tensorflow.keras.optimizers import Adam
    from sklearn.metrics import classification_report,confusion_matrix

    (X_train,y_train),(X_test,y_test) = mnist.load_data()
    X_train,X_test = X_train/255.0,X_test/255.0
    y_train,y_test = to_categorical(y_train,10),to_categorical(y_test,10)

    def build_mlp(activation,layer_config):
        model = Sequential()
        model.add(Flatten(input_shape=(28,28)))
        for units in layer_config:
            model.add(Dense(units,activation))
        model.add(Dense(10,activation='softmax'))

        model.compile(Adam(0.0001),loss='categorical_crossentropy',metrics=['accuracy'])
        return model

    activations = ['relu','tanh','sigmoid']
    layer_configs = [[128,64],[256,128,64],[512,256,128,64]]
    results = {}

    for activatioin activations:
        for config in layer_configs:
            model = build_mlp(activation,config)
            history = model.fit(X_train,y_train,epochs=10,validation_split=0.2,verbose=0,batch_size=32)
            _,accuracy=model.evaluate(X_test,y_test)
            results[(activation,str(config))] = accuracy
            print(activation,config,accuracy)

    plt.figure(figsize=(12,8))
    for key,value in results.items():
        plt.bar(str(key),value)
    plt.xticks(rotation=90)
    plt.show()

    best_activation,best_config = max(results,key=results.get)

    best_model = build_mlp(best_activation,eval(best_config))
    best_model.fit(X_train,y_train,epochs=10,batch_size=32,validation_split=0.2,verbose=0)

    y_pred = best_model.predict(X_test).argmax(1)
    y_test_label = y_test.argmax(1)

    print(best_activation,best_config)
    print(confusion_matrix(y_test_label,y_pred))
    print(classification_report(y_test_label,y_pred))

    plt.figure(figsize=(15,15))
    for i in range(25):
        plt.subplot(5,5,i+1)
        plt.imshow(X_test[i],cmap='gray')
        plt.title(f"Pred:{y_pred[i]},Actual{y_test_label[i]}")
        plt.axis('off')
    plt.show()

    #OPTIMIZER
    import numpy as np
    import pandas as pd
    import time
    import matplotlib.pyplot as plt
    from tensorflow.keras.datasets import mnist
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Flatten, Dense
    from tensorflow.keras.utils import to_categorical
    from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad

    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0
    y_train_cat = to_categorical(y_train, 10)
    y_test_cat = to_categorical(y_test, 10)
    def build_model():
        return Sequential([
            Flatten(input_shape=(28, 28)),
            Dense(128, activation='relu'),
            Dense(64, activation='relu'),
            Dense(10, activation='softmax')
        ]) 

    optimizers = {
        "SGD": SGD(),
        "Adam": Adam(),
        "RMSprop": RMSprop(),
        "Adagrad": Adagrad()
    }

    results = []
    histories = {}

    for name, opt in optimizers.items():
        model = build_model()
        model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])
        start = time.time()
        history = model.fit(x_train, y_train_cat, epochs=10, batch_size=128, verbose=0, validation_split=0.1)
        duration = round(time.time() - start, 2)
        test_acc = model.evaluate(x_test, y_test_cat, verbose=0)[1]
        results.append({"Optimizer": name, "Test Accuracy": test_acc, "Time (s)": duration})
        histories[name] = history.history

    plt.figure(figsize=(14, 6))
    plt.subplot(1, 2, 1)
    for name, hist in histories.items():
        plt.plot(hist['accuracy'], linestyle='--', label=f"{name} train")
        plt.plot(hist['val_accuracy'], label=f"{name} val")
    plt.title("Accuracy")
    plt.legend()

    plt.subplot(1, 2, 2)
    for name, hist in histories.items():
        plt.plot(hist['loss'], linestyle='--', label=f"{name} train")
        plt.plot(hist['val_loss'], label=f"{name} val")
    plt.title("Loss")
    plt.legend()
    plt.tight_layout()
    plt.show()

    y_pred = np.argmax(model.predict(x_test), axis=1)

    plt.figure(figsize=(10, 10))
    for i in range(25):
        plt.subplot(5, 5, i + 1)
        plt.imshow(x_test[i], cmap='gray')
        plt.title(f"Pred:{y_pred[i]} Act:{y_test[i]}",color = 'green' if y_pred[i]==y_test[i] else 'red')
        plt.axis('off')
    plt.tight_layout()
    plt.show()

    #CNN
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense,Flatten,Dropout,Conv2D,MaxPooling2D
    from tensorflow.keras.datasets import mnist
    from tensorflow.keras.utils import to_categorical
    from tensorflow.keras.callbacks import EarlyStopping
    from sklearn.metrics import classification_report,confusion_matrix
    from sklearn.model_selection import train_test_split

    (X_train,y_train),(X_test,y_test) = mnist.load_data()
    X_train,X_test = X_train[...,np.newaxis]/255.0,X_test[...,np.newaxis]/255.0
    y_train_cat,y_test_cat = to_categorical(y_train,10),to_categorical(y_test,10)

    X_train,X_val,y_train_cat,y_val_cat = train_test_split(X_train,y_train_cat,test_size=0.2)

    model = Sequential()
    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))
    model.add(MaxPooling2D((2,2)))
    model.add(Conv2D(64,(3,3),activation='relu'))
    model.add(MaxPooling2D((2,2)))
    model.add(Flatten())
    model.add(Dense(128,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(10,activation='softmax'))
    model.summary()

    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
    earlystop = EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)

    history = model.fit(
        X_train,y_train_cat,
        epochs=20,
        batch_size=128,
        validation_data=(X_val,y_val_cat),
        callbacks=[earlystop]
    )

    loss,acc = model.evaluate(X_test,y_test_cat,verbose=0)
    print(acc,loss)
    y_pred = model.predict(X_test).argmax(1)

    plt.figure(figsize=(10,4))
    for i in range(5):
        plt.subplot(1,5,i+1)
        plt.imshow(X_test[i],cmap='gray')
        plt.title(f"Pred{y_pred[i]}Act:{y_test[i]}")
        plt.axis('off')
    plt.show()

    def plot_metrics(history):
        plt.figure(figsize=(12,5))
        plt.subplot(1,2,1)
        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title('Accuracy over Epochs')

        plt.subplot(1,2,2)
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('Loss over Epochs')

    plot_metrics(history)

    sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='d',cmap='Blues')
    print(classification_report(y_test,y_pred))

    #FCN,RCNN
    import torch
    import torchvision
    from torchvision import transforms
    from PIL import Image
    import matplotlib.pyplot as plt

    fcc = torchvision.models.segmentation.fcn_resnet50(pretrained=True).eval()
    rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True).eval()

    def process_img(image,fcn,rcnn):
        tensor = transforms.ToTensor()(image).unsqueeze(0)
        with torch.no_grad():
            seg = fcn(tensor)['out'].argmax(1).squeeze().cpu().numpy()
        
        det = rcnn([tensor.squeeze(0)])[0]

        fig,ax = plt.subplots(1,3,figsize=(15,5))
        ax[0].imshow(image)
        ax[1].imshow(seg)
        ax[2].imshow(image)
        for x_min,y_min,x_max,y_max in det['boxes'].detach().cpu().numpy():
            ax[2].add_patch(plt.Rectangle((x_min,y_min),x_max-x_min,y_max-y_min,fill=False,color='red'))
        plt.tight_layout()
        plt.show()

    test_image1 = Image.open(r'filelink').convert('RGB')
    process_img(test_image1, fcc,rcnn)

    #CATS AND DOG
    import tensorflow as tf, os, zipfile, matplotlib.pyplot as plt
    from tensorflow.keras.preprocessing.image import ImageDataGenerator
    from tensorflow.keras.applications import VGG16

    # Download & extract dataset
    url="https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
    path=tf.keras.utils.get_file("cats_and_dogs.zip",url,cache_dir=os.getcwd())
    with zipfile.ZipFile(path,"r") as z: z.extractall(os.getcwd())

    train_dir=os.path.join(os.getcwd(),"cats_and_dogs_filtered/train")
    val_dir=os.path.join(os.getcwd(),"cats_and_dogs_filtered/validation")

    # Data generators
    train_gen=ImageDataGenerator(rescale=1./255,rotation_range=20,width_shift_range=0.2,
        height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)
    val_gen=ImageDataGenerator(rescale=1./255)

    train_ds=train_gen.flow_from_directory(train_dir,batch_size=20,class_mode="binary",target_size=(150,150))
    val_ds=val_gen.flow_from_directory(val_dir,batch_size=20,class_mode="binary",target_size=(150,150))

    # Model
    base=VGG16(weights="imagenet",include_top=False,input_shape=(150,150,3))
    base.trainable=False
    model=tf.keras.Sequential([
        base,
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(256,activation="relu"),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(1,activation="sigmoid")
    ])
    model.compile(loss="binary_crossentropy",optimizer=tf.keras.optimizers.RMSprop(2e-5),metrics=["accuracy"])

    # Train
    hist=model.fit(train_ds,steps_per_epoch=100,epochs=30,validation_data=val_ds,validation_steps=50)

    # Predictions
    x,y=next(val_ds)
    preds=model.predict(x)
    class_names=["cat","dog"]
    plt.figure(figsize=(12, 12))
    for i in range(len(x)):
        plt.subplot(4, 5, i+1)  # 4 rows × 5 cols = 20 images (batch_size=20)
        plt.imshow(x[i])
        plt.axis("off")
        pred = class_names[int(preds[i][0]>0.5)]
        true = class_names[int(y[i])]
        plt.title(f'P:{pred} T:{true}')
    plt.tight_layout()
    plt.show()

    # Plot metrics
    plt.plot(hist.history["accuracy"],label="Train Acc")
    plt.plot(hist.history["val_accuracy"],label="Val Acc")
    plt.plot(hist.history["loss"],label="Train Loss")
    plt.plot(hist.history["val_loss"],label="Val Loss")
    plt.legend()
    plt.show()

    #YOLO
    import cv2
    from ultralytics import YOLO

    model = YOLO("yolov8n.pt")
    cap = cv2.VideoCapture(0)

    while True:
        ret, frame = cap.read()
        results = model(frame)
        cv2.imshow("YOLO", results[0].plot())
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
